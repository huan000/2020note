<?php
/**
 * Created by PhpStorm.
 * User: huan
 * Date: 2020/11/20
 * Time: 13:53
 */


/**
 *  正则表达式的考点：
 *         作用：
 *          分割 ，
 *          查找 :
 *          匹配 :  preg_match($pattern,$str,$match);
 *          替换字符串  ： preg_replace('REX','b','a');
 *      通用原子 ：
 *          \d,(0-9) \D,(除了0-9) \w,(数字字母下划线) \W, \s,(空白符) \S (除了空白符)
 *      元字符：
 *          . : 除了换行符外的任意字符
 *          * ：前面出现的次数大于0次
 *          ? : 0次或者一次
 *          ^ : 开头
 *          $ : 结尾
 *          + ： 一次或者多次
 *          {n} :  恰好出现n次
 *          {n,}  :  大于等于n次
 *          {n,m} :   大于等于n次 小于等于m次
 *          [abc] :    集合 a 或者 b 或者 c
 *          () :       整体
 *          [^abc] :   除了a 或者 b 或者 c
 *       模式修正符 ：
 *          i : 不区分大小写
 *          m ： 字符串的每一行分别进行匹配
 *          s :
 *          U :    取消贪婪模式   (或者使用 .*?)
 *          x :  忽略模式中的空白符
 *
 */





/**
 *   2.9 目录相关操作
 *      fopen();  用来打开一个文件
 *      fwrite();    网文件中进行写入
 *      fread()；    读取文件
 *      fgets();     获取一行
 *      fgetc();     获取一个字符
 *
 *      不需要fopen 打开的函数
 *      file_get_contents();
 *      file_put_contents();
 *
 *      访问远程文件：
 *      php.ini 中开启 allow_url_fopen
 *
 *      目录操作的相关函数：
 *      basename();
 *      dirname();
 *      pathinfo();
 *
 *      目录读取的相关函数:
 *      opendir();  readdir();  closedir();  rewinddir();
 *
 *      目录删除的相关函数：
 *      rmdir();
 *
 *      文件大小：
 *      filesize();
 *
 *      目录大小获取：
 *      disk_free_space();   disk_total_space();
 *
 *      文件类型：
 *      filetype();
 *
 *      重命名文件或者目录:
 *      rename();
 *
 *      文件截取:
 *      ftruncate();
 *
 *      文件属性:
 *      file_exists();  is_readable(); is_writable(); is_executable();
 *      filectime(); fileatime(); filemtime();
 *
 *      文件锁: flock
 *
 *
 *      tip:
 *      在文件的开头不断的追加写入hello.txt
 *      1. 打开文件
 *          $file = './hello.txt';
 *          $handle = fopen($file,'r');
 *      2. 将文件的内容读取出来， 在开头加入hello world
 *          $content = fread($handle,filesize($file));
 *          $content = 'hello world'.$content;
 *          fclose($handle);                                  //防止直接写的话会覆盖后面的内容 所以先进行关掉
 *      3. 将拼接好的字符串写入到文件中
 *          $handle = fopen($file,'w');
 *          fwrite($handle,$content);
 *          fclose($handle);
 *
 *
 *      遍历目录：
 *      function loopDir($dir){
 *          $handle = opendir($dir);
 *          while(false !== ($file = readdir($handle))){
 *              if($file != '.' && $file != '..'){
                    if(filetype($dir.'/'.$file) == 'dir'){
 *                          loop($dir.'/'.$file);
 *                  }else{
 *                          echo $file;
 *                  }
 *              }
 *          }
 *      }
 *
 */

/**
 *   会话控制 ：
 *      cookie 写操作 ：　
 *          setcookie($name,$value,$expire,$path,$domain,$secure);
 *          读取:  $_COOKIE
 *          删除: setcookie($name,'',time()-1);
 *
 *      cookie的优缺点：
 *          优点：不会浪费服务器的资源
 *          缺点： 存储在浏览器端 不安全 ，浏览器会禁止到cookie的使用
 *
 *      session :
 *          使用 ：
 *              session_start();
 *              $_SESSION
 *          删除：
 *              $_SESSION = [];
 *          清空session 文件
 *              session_destroy();
 *
 *      session：配置
 *          session.auto_start  ： 是否自动开启session_start();
 *          session.cookie_domain : 存储sessionid的cookie的作用域
 *          session.cookie_lifetime :  存储sessionid的cookie的生存时间
 *          session.cookie_path : 存储sessionid的cookie的路径
 *          session.save_path : 存储session数据的文件实在哪个路径下的
 *          session.use_cookies : 是否使用cookie来传递sessionid
 *          session.use_trans_sid :  是否使用传递的方式来传递sid
 *          session.gc_probability : 1
 *          session.gc_divisor : 100       每100次会有一次清空的机会
 *          session.gc_maxlifetime :  文件的生存时间，如果超过这个时间就有可能进行清空
 *
 *          session.save_handler :  session 的存储句柄是什么 可以存储到memcache之类的介质中
 *
 *      优点和缺点 ：
 *          缺点是占用服务器资源，但是数据比较安全 ， 分布式的话可以存储到redis中
 *
 *      传递session_id的问题：
 *          1.可以通过url 进行传递 ：
 *              session_name().'='.session_id();
 *          2.可以使用 SID 常量  就是  session_name 和 session_id 的拼接
 *
 */


/**
 *      网络协议的相关考点：
 *          200： 正常处理
 *          204： 服务器接受的请求成功处理了，报文中不含实体的主体部分
 *          206： 服务器接受的请求成功处理了，报文中含有部分的主体部分
 *          301： 永久性重定向
 *          302： 临时重定向
 *          304： not modified 缓存
 *          400： 请求中有语法错误
 *          401： 请求需要认证信息
 *          403： 请求资源的访问被服务器拒绝了
 *          404： 服务器找不到请求的资源
 *          500： 服务器内部错误
 *          503： 服务器超负载
 *
 *
 *
 *      OSI 七层模型 ：
 *          物理层 ： 建立， 维护， 断开物理链接
 *          数据链路层 ： 建立逻辑链接，进行硬件地址寻址，差错校验功能
 *          网络层： 进行逻辑地址寻址，实现不同网络之间的路径选择
 *          传输层:  定义传输数据的协议端口号，以及流控和差错校验 (协议有tcp udp)
 *          会话层:  建立管理控制会话
 *          表示层： 数据的表示，安全，压缩
 *          应用层： 网络服务与最终用户的一个接口
 *
 *          协议： HTTP FTP TFTP SMTP SNMP DNS TELNET HTTPS POP3 DHCP
 *          http的请求方法： get post head options put delete trace
 *
 *      get 和 post 的区别：
 *          get 可以被收藏为书签   post 不可以收藏为书签
 *          get 长度有限制2048字符  post 没有限制
 *          get 只能传递asc码  post 可以传递二进制
 *          get 按后退按钮的时候可以后退  post 按后退按钮的时候需要重新提交
 *          get 的安全性低  post 的安全性高
 *
 *
 *
 */

/**
 *  linux 基础考点：
 *      常用命令 ：
 *          系统安全：
 *              sudo ，su, chmod, setfacl
 *          进程管理：
 *              w, top, ps, kill, pkill, pstree, killall
 *          用户管理：
 *              id, usermod, useradd, groupadd, userdel
 *          文件系统：
 *              mount, umount, fsck, df, du
 *          系统关机和重启：
 *              shutdown, reboot
 *          网络应用：
 *              curl, telnet, mail, elinks
 *          网络测试：
 *              ping, netstat, host
 *          网络配置：
 *              hostname, ifconfig
 *          常用工具：
 *              ssh,screen,clear,who,date
 *          软件包管理：
 *              yum， rpm
 *          文件查找和比较
 *              locate，find
 *          文件内容的查看：
 *              head，tail，less，more
 *          文件处理：
 *              touch，unlink，rename，ln，cat
 *
 *
 *      定时任务：
 *          crontab -e
 *          * * * * *   (分时日月周)
 *
 *          at
 *          at 2:00 tomorrow   一次性执行而不是循环执行
 *
 *      vi编辑器：
 *          / 向下查找
 *          ? 向上查找
 *          替换：
                :s/text1/text2 用于将光标所在段落搜索到的第一个”text1“替换为”text2“；
                :s/text1/text2/g 用于将光标所在段落的所有”text1“替换为”text2“；
 *          删除复制和粘贴：
 *              dd ： 删除(剪切)光标所在的那一行
 *              ndd :  	n 为数字，删除(剪切)光标所在的向下 n 行
 *              yy : 复制光标所在那一行
 *              nyy : n 为数字，复制光标所在的向下 n 行
 *              p : 将已复制的书在光标下一行粘贴，P 则为在光标上一行粘贴
 *              x : 行操作，x 为向后删除一个字符(相当于 del 键)，X 为向前删除一个字符，相当于 Backspace,退格键
 *
 */

/**
 *  mysql 基础类考点：
 *      数据类型：
 *      int(3) :  3对大多数应用是没有意义的，不会限制值的合法范围，只会影响显示字符的个数
 *              (3) 如果存了12  加上zerofill 那么就是012
 *
 *      decimal : decimal可以存储比bigint还大的整数，可以用于存储精确的小数
 *              float 和 double类型支持使用标准的浮点进行近似的计算
 *
 *      varchar : 可以用于存储可变类型的长度的字符串，它比定长更加节省空间
 *          额外使用1或者2个字节记录字符串的长度，列长度小于255字节，使用1个字节表示
 *          否则使用2个字节表示，如果内容超出了指定的长度会被截断
 *
 *      char : 定长 ，根据定义的长度分配足够的空间，char会根据需要采用空格来进行填充
 *           char 适合存储很短的字符串 或者所有的值都接近同一个长度
 *          如果超出设定的长度也会被截断
 *
 *
 *      对于经常变更的数据，char比varchar更好，char不容易产生碎片，
 *      对于非常短的列，char比varchar在存储上更加有效率
 *      只分配真正需要的空间，更长的列会消耗更多的内存
 *
 *      尽量避免使用blob和text 类型，查询时会使用临时表，导致严重的性能开销
 *
 *      日期和时间类型：
 *          尽量使用timestamp，比datetime空间效率更高，用整数保存时间戳的格式
 *          通常不方便处理
 *
 *      列属性：
 *          auto_increment :  自增
 *          default :       默认值
 *          not null :      非null
 *          zerofill :      填充0
 *
 *       mysql 的链接和关闭 ：
 *          -u    user
 *          -p    password
 *          -h    host
 *          -P    PORT
 *
 *      MYSQL 数据表的表引擎:
 *          innodb ： 默认的事务型引擎，最重要最广泛的存储引擎，性能非常优秀
 *          数据存储在共享表空间(表的数据和表的索引都在一个表中存放)，可以通过配置分开
 *          对主键查询的性能高于其他存储引擎
 *          通过一些机制和工具支持真正的热备份，支持崩溃后的安全恢复，支持行级锁
 *          支持外键
 *
 *          MyISam : 5.1 之前是默认的存储引擎 ，不支持事务，不支持崩溃后的安全恢复
 *          表存储是在两个文件 MYD 和 MYI
 *
 *      其他的表引擎:
 *          csv,memory,archive
 *
 *      mysql 的锁机制 ：
 *          当多个查询同一时刻进行数据的修改时，就会产生并发控制的问题
 *          共享锁(读锁) ： 不堵塞，多个用户可以同一个时刻读取一个资源，互不干扰
 *          排他锁(写锁) ： 一个写锁可以堵塞其他的写锁和读锁，这样只可以一个人进行
 *              写入，防止其他用户读取正在写入的资源
 *
 *      mysql 事务:
 *           事务是由下层引擎实现的，所以同一个事务当中，使用多种存储引擎不靠谱，在
 *          非事务的表上执行事务操作 mysql 不会发出提醒，也不会报错
 *
 *      存储过程：
 *          为以后的使用而保存的一条或者多条mysql语句的合集，就是业务逻辑和流程的集合
 *
 *
 * 索引类考点：
 *      mysql 索引的基础和类型
 *        索引对性能的影响 ： 大大减少服务器需要扫描的数据量
 *                  帮助服务器避免排序和临时表，将随机io变成顺序io，大大提高查询速度
 *                  降低写的速度，占用磁盘
 *
 *        索引的使用场景： 对于非常小的表，大部分情况下全表扫描效率更高，中到大型表，
 *                  索引非常有效，特大型的表，建立和使用索引的代价随之增长，可以使用
 *                  分区技术来解决
 *
 *      索引类型：
 *          普通索引： 最基本的索引，没有任何约束限制
 *          唯一索引： 于普通索引类似，但是具有唯一性约束
 *          主键索引:  特殊的唯一索引，不允许有空值
 *          组合索引： 将多个列组合在一起创建索引，可以覆盖多个列
 *          外键索引： 只有innodb类型的表才可以使用外键索引，保证数据的一致性，完整性和实现级联操作
 *
 *
 *
 *      一个表只能有一个主键索引，可以有多个唯一索引，主键索引一定是唯一索引，唯一索引
 *      不一定是主键索引，主键可以和外键构成完整性约束，防止数据不一致
 *
 *      索引的创建原则：
 *          最适合索引的列是出现在where子句中的列，索引列的基数越大索引的效果越好
 *         避免创建过多的索引，索引会额外占用磁盘空间，降低写操作效率，主键尽可能
 *          选择较短的数据类型，可以有效减少索引的磁盘占用提高查询效率
 *
 *      注意事项;
 *          1. 复合索引遵循前缀原则
 *          2. like 查询 %不能在前 如果 %name%  前面有百分号了 那么索引不能命中
 *          3. column is null 也是可以使用索引的
 *          4. 如果mysql认为查询索引比不查询还慢 那么就不会使用索引， 例如：
 *              where id > 1 and id < 100
 *          5. 如果or前面有索引但是后面的列没有索引， 那么所有的索引都不会用到
 *          6. where id = 100；  如果 id是字符串类型 那么不会使用到
 *
 *
 *
 * sql 语句编写的特点：
 *      考点 ： mysql的关联update语句
 *          update A,B set A.c1 = B.c1,A.c2 = B.c2 where A.id = B.id and b.age>50
 *
 *          update A inner join B on A.id = B.id set A.c1 = B.c1,A.c2 = B.c2
 *          where B.age >50
 *
 *
 *  查询优化考点 ：
 *       查找分析查询速度慢的原因:
 *          1. 记录慢查询日志进行分析
 *
 *          2. 开启show profile ， 设置 set profiling=1 开启。服务器上执行的所有语句
 *          会检测消耗的时间，存到临时表中
 *
 *          3. 使用explain，查询使用的语句
 *
 *       优化查询过程中的数据访问：
 *          访问数据太多导致性能下降. 确定应用程序是否在检索大量超过需要的数据，可能是
 *          太多的行或者太多的列
 *
 *          查询不需要的记录，使用limit解决
 *          多表关联返回全部的列，指定 列的字段
 *
 *          重复查询相同的数据，可以缓存数据，下次直接读取缓存
 *
 *       可以通过改变数据库和表的结构，修改数据表的范式：
 *          可以通过一些表的冗余字段来提高查询的效率，避免多表查询
 *
 *      优化长难的查询语句：
 *          一个复杂的查询还是多个简单的查询:
 *          mysql内部每秒能够扫描内存中上百万行的数据，相比之下，响应数据给客户端就要慢得多
 *          使用尽可能少的查询是好的，但是有时将一个大的查询分解为多个小的c
 *
 *      切分查询：
 *          将一个大的查询分为多个小的相同的查询，一次删除一千万的数据要比一次删除
 *          1万，暂停一会的方案更加损耗服务器的开销
 *
 *      优化特定类型的查询语句：
 *          优化关联查询：
 *          确定on 或者 using 子句的列上是否有索引
 *          确保group by 或者 order by 中只有一个表中的列，这样mysql 才有可能使用索引
 *
 *
 *  mysql 高可用拓展和高可用考察点：
 *      简述 mysql 分表操作和分区的工作原理，分别说说分表和分区的使用场景和各自的优缺点
 *
 *      分区的原理：
 *          工作原理：
 *              对用户而言，分区表是一个独立的逻辑表，但是底层mysql将其分成了多个物理
 *              子表，这对用户来说是透明的，每一个分区表都会使用一个独立的表文件
 *              对于php是没有任何感知的
 *          创建表的时候使用 partition by 定义每个分区存放的数据，执行查询时，
 *          优化器会根据分区定义过滤那些没有我们需要数据的分区，这样查询只需要查询
 *          所需数据所在的分区即可
 *
 *      分区的目的：
 *          分区的主要目的是将数据按照一个较粗的粒度分在不同的表中，这样可以将相关的
 *          数据存放在一起，而且想一次性删除整个分区也很简单
 *
 *      使用场景：
 *          表非常大，无法全部存在内存中，或者只在表的最后有热点数据，其他都是历史数据
 *          分区表的数据更易于维护，可以对独立的分区进行独立的操作
 *          可以备份和恢复独立的分区
 *          一个表只能有1024个分区
 *          分区表中无法使用外键索引
 *          需要对现有表的结构进行修改
 *          所有分区都必须使用相同的存储引擎
 *          分区函数中可以使用的函数和表达式会有一些限制
 *          某些存储引擎是不支持分区的
 *
 *      分库分表的原理：
 *          工作原理：
 *          通过一些hash算法或者工具实现将一张数据表垂直或者水平进行物理切分。
 *          使用场景：
 *          1. 单表记录达到百万或者千万级别
 *          2. 解决表锁的问题
 *
 *      水平分割：
 *
 *          使用场景：
 *          1.表中的数据本身就有独立性，例如表中分别记录各个地区的数据或者不同
 *          时期的数据，
 *          2.需要把数据存放在多个介质上
 *
 *          缺点：
 *          1.给应用增加复杂度，，查询所有数据都需要union操作
 *          2.在许多数据库应用中，这种复杂度通常查询时需要多个表名会超过它带来的优点，查询时
 *
 *
 *          垂直分表：
 *          使用场景：
 *          1.如果一个表中的某些列常用，而另外一些列不常用
 *          2.可以使数据行变小，一个数据页能存储更多的数据，查询时减少io的次数
 *
 *          缺点：
 *          1.管理冗余列，所有的查询需要join操作
 *          2.有些分表的策略基于应用层的逻辑算法，一旦逻辑算法改变了，整个分表逻辑都会改变，拓展性差
 *
 *
 *      mysql的复制原理和负载均衡：
 *          mysql 主从复制的工作原理：
 *          在主库上把数据更改记录到二进制日志中。
 *          从库将主库的日志复制到自己的中继日志中。
 *
 *          mysql 主从复制解决的问题：
 *          数据分布： 随意停止或开始复制，并在不同地理位置分布数据备份
 *          负载均衡： 降低单个服务器的压力
 *
 *          高可用和故障切换： 帮助应用程序避免单点失败
 *
 *      mysql 的安全性考点：
 *          sql语句应该考虑那些安全性的问题：
 *          1. 使用预处理语句防止sql注入
 *          2. 写入数据库的数据要进行特殊的字符转义
 *          3. 查询错误信息不要返回给用户，将错误记录到日志
 *
 *      mysql 的其他安全设置：
 *          1. 定期做数据备份
 *          2. 不给查询用户root权限，合理分配权限
 *          3. 关闭远程数据库权限
 *          4. 修改root口令，不用默认口令，使用较复杂的口令
 *          5. 删除多余的用户
 *          6. 改变root用户的名称
 *          7. 限制一般用户浏览其他的库
 *          8. 限制用户对数据文件的访问权限
 *
 */


/**
 *  常见算法相关考点：
 *      常见数据结构的特征:
 *          array:
 *          数组：
 *          特性：
 *
 *          stack: 栈，和队列相似，一个带有数据存储特性的数据结构
 *              特性： 存储数据是先进后出的，栈只有一个出口，只能从栈的顶部增加和移除元素
 *          heap: 堆，
 *          list: 线性表，由零个或多个元素组成的有限序列
 *          队列： 先进先出
 *
 *      真题 ： 用php实现一个双向的队列
 *           array_shift : 头部移除
 *           array_unshift : 头部插入
 *           array_pop ： 从尾部移除
 *           array_push :  从尾部插入
 *
 *
 *
 *      其他逻辑算法的考点：
 *      1,1,2,3,5,8,13,21,34... 求第30个数是多少，用代码来实现
 *          $arr = [1,1];
 *      for($i=2;$i<30;$i++){
            $arr[$i] = $arr[$i-1] + $arr[$i-2];
 *      }
 *
 *
 *  模拟内置函数的相关考点：
 *      实现字符串翻转：
 *      function str_rev($str){
 *          for($i=0;true;$i++){
                if(!isset($str[$i])){
 *                  break;
 *              }
 *          }
 *          $return  = '';
 *          for($j=$i-1;$j>=0$j--){
                $return .= $str[$j];
 *          }
 *
 *          return $return;
 *      }
 *
 *
 *  写一个函数,要求不使用array_merge完成多个数组的合并。
 *      function array_mer($arr...){
 *          $return = [];
            $arrays = func_get_args();
 *          foreach($arrays as $arr){
                if(is_array($arr)){
 *                  foreach($arr as $val){
                        $return[] = $val;
 *                  }
 *              }
 *          }
 *          return $return;
 *      }
 *
 */



/**
 *  高并发和大流量的解决方案的考点：
 *      1. php如何解决网站大流量和高并发的问题。
 *          高并发架构的相关概念
 *              并发：
 *              在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕
 *              之间，且这几个程序都是在同一个处理机上运行，但任一时刻点上只有一个
 *              程序在处理机上运行
 *
 *              网站中的高并发：
 *              互联网时代，并发指的是并发访问，也就是在某个时间点，有多少个访问同时
 *              到来
 *
 *              通常一个系统的日pv在千万以上，就有可能是一个高并发系统。
 *
 *              高并发的问题，我们应该关心的问题
 *              qps：每秒钟请求或者查询的数量，在互联网领域就是每秒响应的请求数(指http请求)
 *              吞吐量： 单位时间内处理的请求数量 (通常由qps和并发数决定)
 *              响应时间 ： 就是从请求发出到收到响应花费的时间。
 *              pv: page view ,即页面的浏览量或者点击量，一个访客在24小时内访问页面的数量
 *              uv ： user view 一个网站用户访问的数量
 *             日网站带宽 ： pv/统计时间(36400) * 平均页面的大小
 *
 *              qps不等于并发连接数： qps是每秒http请求的数量，并发连接数是系统同时处理
 *              请求的数量
 *
 *              并发测试工具：
 *              ab -c 100 -n 5000              c(并发数) n(总共请求次数)
 *
 *          高并发的解决方案：
 *              流量优化： 防盗链处理
 *              前端优化： 减少http请求，把一些css进行合并 , cdn加速
 *              添加异步请求
 *              启用浏览器的缓存和文件的压缩
 *
 *          数据库优化：
 *              数据库缓存，分库分表，分区操作，读写分离，负载均衡
 *
 *          服务器优化：
 *              负载均衡
 *
 *
 *
 *  具体优化方案:
 *          防盗链处理：
 *          1. 程序方面防止：
 *              通过referer 或者签名的方式 ， 在请求头信息中携带，然后程序中一但
 *              检测不是本网站进行访问的话，那么立即阻止该请求
 *
 *              nginx :
 *                  模块 ngx_http_referer_module 用于阻挡来源非法的域名请求
 *                  指令 valid_referers ,全局变量 $invalid_referer
 *
 *              valid_referers none| blocked | server_name| string ..
 *                  none : "referer" 来源头部为空的情况
 *                  blocked :  "referer" 来源头部不为空，但是里面的值被代理后者
 *                          被防火墙删除了，这些值都不以 http:// 或者 https:// 开头。
 *
 *          案例 ：
 *              location ~.*\.(gif|jpg|png)$
 *              {
                        valid_referers none blocked imooc.com *.imooc.com;
 *                      if($invalid_referer){
                            rewrite ^/ http://www.imooc.com/403.png
 *                      }
 *              }
 *
 *          漏洞 ： 传统防盗链可以使用伪造referer 来制造漏洞
 *                  可以使用加密签名
 *
 *          使用第三方模块 HttpAccessKeyModule 实现Nginx防盗链
 *              accessKey on | off
 *              accessKey_hashmethod md5 | sha-1 签名加密方式
 *              accessKey_arg GET 参数的名称
 *              accessKey_signature  加密规则
 *
 *          案例 ：
 *              location ~.*\.(gif|jpg|png|flv)$
 *              {
                    accesskey on;
 *                  accessKey_hashmethod md5;
 *                  accessKey_arg "key";
 *                  accessKey_signature "mypass$remote_addr";
 *              }
 *
 *             然后php 这边的客户端通过 get的方式 key.签名 进行传递
 *
 *
 *
 *  浏览器缓存和数据压缩技术：
 *          缓存分类：
 *          http缓存模型中，如果请求成功会有三种情况。
 *          1. 200 from cache： 直接从本地缓存中获取响应，最快速，最省流量，因为根本
 *             没有向服务器发送请求
 *          2. 304 not modified： 协商缓存，浏览器在本地没有命中的情况下，请求头中发送
 *             一定的校验数据到服务端，如果服务端数据没有改变浏览器从本地缓存响应，返回304
 *              只响应头信息，不响应返回的body部分
 *          3. 200 ok ： 以上两种缓存全部都失败，服务器返回完整的响应。没有用到缓存，相对
 *              最慢
 *
 *          相关header：
 *          pragma ： http1.0 时代遗留的产物，该字段被设置为no-cache时，会告知浏览器
 *             禁用本地缓存，即每次都向服务器发送请求。
 *
 *          expires : http1.0 时代用来启用缓存的字段，expire值对应一个形如
 *             Thu,31 Dec 2037 23:55:55 GMT的格林威治时间。告诉浏览器缓存实现的时刻，
 *             如果还没有到该时刻，表明缓存有效，无需发送请求
 *
 *             但是如果浏览器和服务器时间不一致那么缓存时间无法很好的进行计算
 *
 *          cache-control : http1.1针对expire时间不一致的解决方案，运用cache-control
 *              告知浏览器缓存过期的时间间隔而不是时刻，即使具体时间不一致，也不影响
 *              缓存的管理
 *              选项：
 *              no-store：禁止浏览器缓存响应
 *              no-cache: 不允许直接使用本地缓存，先发起请求和服务商协商
 *              max-age=3600； 告知浏览器该响应本地缓存有效的最长期限，以秒为单位
 *
 *          优先级： pragma > cache-control > expires
 *
 *          协商缓存： 当浏览器没有命中本地缓存，如本地缓存过期或者响应中声明不允许
 *              直接使用本地缓存，那么浏览器肯定会发起服务端请求
 *              服务端会验证数据是否修改，如果没有修改会通知浏览器使用本地缓存
 *
 *          Last-Modified ：相应的时候告知这个资源的最后修改时间是多少，下次请求的时候
 *              带上这个数值，对比后知道资源是否被修改，如果没有修改就返回304
 *                  再次请求的时候带上 If-Modified-Since. 和 Last-Modified 是相等的
 *
 *          ETag ： http1.1推出，文件的指纹标识符，如果文件内容修改，指纹就会改变
 *
 *          If-None-Match ： 本地缓存失效，会携带此值去请求服务端，服务端判断该资源
 *              是否改变，如果没有改变，直接使用本地缓存，返回304
 *
 *      适合缓存的内容：
 *          不变的图像，如logo，图标等。
 *          js.css 静态文件， 可下载的内容，媒体文件
 *
 *      建议使用的协商缓存：
 *          html文件， 经常替换的图片，经常修改的js，css文件
 *
 *      Nginx配置缓存策略
 *      add_header 指令： 添加状态码2xx和3xx的响应头信息
 *      add_header name value [always];
 *      可以设置 Pragma/Expires/Cache-Control, 可以继承
 *
 *      expires 指令 ： 通知浏览器过期时长。
 *      expires time;
 *      如果 expires 为负值的时候表示Cache-Control：no-cache;
 *      如果 为正或者0时，就表示 Cache-Control：max-age=指定的时间；
 *
 *           location ~.*\.(gif|jpg|png|flv)$
 *              {
                   expires 30d;
 *              }
 *
 *      当expires 为max 的时候，那么 cache-control 设置的值为10年
 *
 *      协商缓存的相关配置：
 *      Etag指令： 指定签名   on | off；
 *
 *      前端代码和资源的压缩：
 *      优势 ： 让资源文件更小，加快在网络中的传输，让网页更快的展现，降低带宽和流量
 *          的开销
 *
 *      javascript,css 代码压缩：
 *          去掉多余的空格和回车，替换长变量名，简化一些代码的写法等。
 *
 *      图片压缩：
 *      除了代码的压缩外，有时对图片的压缩也是很有必要的，一般情况下图片在web系统的比重
 *      都比较大
 *
 *      gzip 压缩：
 *      gzip on | off;
 *      gzip_comp_level [1-9]; 推荐6 压缩级别(级别越高，压得越小，越浪费cpu计算资源)
 *      gzip_disable;       正则匹配，什么样的uri不进行gzip
 *      gzip_http_version 1.0|1.1;  开始压缩的http协议版本
 *      gzip_proxied;           设置请求者代理服务器，该如何缓存内容
 *      gzip_types text/plain application/xml;      对那些文件的类型进行压缩
 *      gzip_vary on|off;         是否传输gzip的压缩标志
 *
 *      如果响应头显示 Content-Encoding ：gzip; 那么就是压缩了
 *
 *      动态语言静态化：
 *      将现有的php等动态语言的逻辑代码生成为静态html文件，用户访问动态脚本重定向
 *      到静态html文件的过程
 *
 *      为什么要静态化:
 *      动态脚本通常会做逻辑计算和数据查询，访问量越大，服务器压力越大
 *      访问量大的时候会造成cpu负载过高，数据库服务器压力过大
 *
 *      静态化的实现方式：
 *      1. 使用模板引擎： 可以使用smarty生成html
 *
 *      2. 利用ob系列的函数：
 *          ob_start();     打开输出缓冲
 *          ob_get_contents();      返回输出缓冲区的内容
 *          ob_clean();     清空输出缓冲区
 *          ob_end_flush(); 冲刷出输出缓冲区的内容并且关闭输出缓冲
 *
 *
 *
 *
 *          $cachename = md5(__FILE__).'.html';
 *          $cache_lifetime = 3600;
 *          if(filectime(__FILE__) <= filectime($cache_name) && file_exists($cachename) && filectime($cachename) + $cache_lifetime > time()){
 *              include $cachename;
 *              exit;
 *          }
 *          ob_start();
 *          HTML代码。。。
 *          ob_get_contents();
 *          ob_end_flush();
 *          $handle = fopen($cache_name,'w');  写入输出缓冲区的内容到一个文件
 *          fwrite();
 *
 *
 *  并发处理：
 *      进程： 进程是一个执行中的程序。
 *      进程的三态模型： 多道程序系统中，进程在处理器上交替运行，状态不断发生变化
 *      进程的运行： 当一个进程在处理机上运行时，则称该进程处于运行状态。处于此状态
 *              的进程的数目小于等于处理器的数目。对于单处理机系统，处于运行状态的
 *              进程只有一个。
 *      进程的就绪： 当一个进程获得了除处理机以外的一切所需资源，一旦得到处理机即可运行，
 *              则称此进程处于就绪状态。
 *      进程的阻塞： 也称为等待或者睡眠状态，一个进程正在等待某一事件发生而暂时停止运行
 *
 *      由于用户的并发请求，为每一个用户都创建一个进程显然是行不通的，从系统资源开销
 *      方面或者是响应用户请求的效率方面来看，因此操作系统中线程的概念便被引进了。
 *      线程，有时候被称为是轻量级进程(lwp),是程序执行流的最小单元;
 *
 *      线程是进程中的一个实体，是被系统独立调度和分配的基本单位，线程自己不拥有
 *      系统资源，只拥有一点儿在运行中必不可少的资源但它可与同属一个进程的其他线程
 *      共享进程所拥有的全部资源。
 *
 *      一个线程可以创建和撤销另一个线程，同一个进程中的多个线程之间可以并发执行。
 *
 *      每一个程序都至少有一个线程，如果程序只有一个线程，那就是程序本身
 *
 *      线程和进程的区别
 *      1. 线程是进程内的一个执行单元，进程内至少有一个线程，他们共享进程的地址空间，
 *          而进程有自己独立的地址空间
 *      2. 进程是资源分配和拥有的单元，同一个进程内的线程共享进程的资源
 *      3. 线程是处理器调度的基本单位，但是进程不是
 *      4. 两者都可以进行并发的执行
 *      5. 每个独立的线程有一个程序运行的入口，顺序执行序列和程序的出口，但是线程不能够
 *         独立执行，必须依存在程序应用中，由应用程序提供多个线程执行控制
 *
 *      线程和协程的区别：
 *      1. 一个线程可以有多个协程，一个进程也可以单独拥有多个协程（线程是操作系统控制，
 *          协程是程序员进行控制的）
 *      2. 线程和进程都是同步机制，而协程则是异步
 *      3. 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态
 *
 *      多进程：
 *      同一个时间里，同一个计算机系统如果允许两个或者两个以上的进程处于运行状态，这就是
 *      多进程（边玩游戏边听歌）
 *      多线程：
 *      线程就是把一个进程分为多个片，每一片都可以是一个独立的流程，于多进程的区别是只会
 *      使用一个进程的资源，线程间可以直接通讯
 *
 *      单进程单线程： 一个人在一个桌子上吃饭
 *      单进程多线程： 多个人在一个桌子上吃饭
 *      多进程单线程： 多个人每个人在自己的桌子上吃饭
 *
 *      php并发编程实践：
 *      1.php的swoole拓展
 *      2.消息队列 进行异步发送邮电的案例
 *
 *
 *
 *
 *  数据库缓存优化：
 *      什么是数据库缓存：
 *
 *
 *
 *  web 服务器负载均衡：
 *      七层负载均衡： nginx的实现方式
 *          基于url等应用层信息的负载均衡
 *          nginx的proxy是它一个很强大的功能，实现了七层负载均衡，能够自动剔除不正常
 *          的服务器
 *
 *        负载均衡策略：
 *          内置策略： ip hash，加权轮询
 *
 *          拓展策略： fair策略，通用hash策略，一致性hash策略
 *
 *
 *          加权轮询策略： 首先将请求都分配给高权重的机器，直到该机器的权值降到了比其他
 *              机器低，才开始将请求分给下一个高权重的机器
 *          ip hash： ip hash 是一种变向的轮询算法
 *          fair 策略： 根据后端服务器的响应时间，判断负载情况，从中选出负载最轻的机器
 *              进行分流
 *          通用hash和一致性hash： 通用hash比较简单，可以以nginx内置的变量为key进行hash，
 *              一致性hash采用了nginx内置的一致性hash环，支持memcache
 *
 *          nginx配置：
 *          http{
                upstream cluster{
 *                  server ser1;
 *                  server ser2;
 *                  server ser3;
 *              }
 *              server {
                    listen 80;
 *                  location / {
                        proxy_pass http://cluster;
 *                  }
 *              }
 *          }
 *
 *      
 *
 *
 *
 *
 *      四层负载均衡：
 *
 *
 */

